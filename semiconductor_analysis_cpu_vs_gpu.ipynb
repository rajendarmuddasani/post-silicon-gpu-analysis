{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Silicon Semiconductor Data Analysis: CPU vs GPU Performance Comparison\n",
    "\n",
    "This notebook demonstrates the performance difference between CPU and GPU computing for analyzing large-scale post-silicon semiconductor test data. We'll perform computationally intensive operations including data preprocessing, statistical analysis, and machine learning model training.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Post-silicon validation generates massive amounts of test data from semiconductor chips. Analyzing this data requires significant computational resources. This notebook compares:\n",
    "\n",
    "- **CPU Processing**: Traditional computing on your laptop\n",
    "- **GPU Processing**: Accelerated computing using Google Colab's GPU\n",
    "\n",
    "We'll measure execution time for identical operations and calculate the speedup achieved with GPU acceleration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Hardware Detection\n",
    "\n",
    "First, we'll detect the available hardware (CPU or GPU) and install necessary packages. The notebook automatically adapts to the available hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import platform\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SYSTEM INFORMATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Processor: {platform.processor()}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q numpy pandas scikit-learn matplotlib seaborn cupy-cuda12x 2>/dev/null || pip install -q numpy pandas scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and detect GPU\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Try to import CuPy for GPU acceleration\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"âœ“ GPU DETECTED - CuPy successfully imported\")\n",
    "    print(f\"âœ“ GPU Device: {cp.cuda.Device(0).compute_capability}\")\n",
    "    print(f\"âœ“ GPU Memory: {cp.cuda.Device(0).mem_info[1] / 1e9:.2f} GB\")\n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"âœ— GPU NOT AVAILABLE - Using CPU only\")\n",
    "    print(\"  To enable GPU: Runtime -> Change runtime type -> GPU\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"COMPUTE MODE: {'GPU ACCELERATED' if GPU_AVAILABLE else 'CPU ONLY'}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Semiconductor Test Data\n",
    "\n",
    "We'll load the synthetic post-silicon semiconductor test data. This dataset contains 50,000 chips with 100 test parameters each, representing voltage, current, frequency, temperature, power, timing, leakage, and noise measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(\"Loading semiconductor test data...\")\n",
    "df = pd.read_csv('data/semiconductor_test_data.csv')\n",
    "\n",
    "print(f\"\\nDataset Shape: {df.shape}\")\n",
    "print(f\"Total Chips: {len(df):,}\")\n",
    "print(f\"Total Features: {df.shape[1] - 4}\")\n",
    "print(f\"\\nPass/Fail Distribution:\")\n",
    "print(df['pass_fail'].value_counts())\n",
    "print(f\"\\nMemory Usage: {df.memory_usage(deep=True).sum() / 1e6:.2f} MB\")\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize pass/fail distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Pie chart\n",
    "colors = ['#90EE90', '#FFB6C6']  # Light green for PASS, light red for FAIL\n",
    "df['pass_fail'].value_counts().plot(kind='pie', ax=axes[0], autopct='%1.1f%%', \n",
    "                                     colors=colors, startangle=90)\n",
    "axes[0].set_ylabel('')\n",
    "axes[0].set_title('Chip Test Results Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Bar chart\n",
    "df['pass_fail'].value_counts().plot(kind='bar', ax=axes[1], color=colors)\n",
    "axes[1].set_xlabel('Test Result', fontsize=12)\n",
    "axes[1].set_ylabel('Count', fontsize=12)\n",
    "axes[1].set_title('Chip Test Results Count', fontsize=14, fontweight='bold')\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "Before analysis, we need to prepare the data by extracting numerical features and creating labels. We'll separate the feature columns from metadata columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for analysis\n",
    "# Extract numerical features (exclude chip_id, lot_id, wafer_id, pass_fail)\n",
    "feature_cols = [col for col in df.columns if col not in ['chip_id', 'lot_id', 'wafer_id', 'pass_fail']]\n",
    "X = df[feature_cols].values\n",
    "y = (df['pass_fail'] == 'PASS').astype(int).values\n",
    "\n",
    "print(f\"Feature Matrix Shape: {X.shape}\")\n",
    "print(f\"Label Vector Shape: {y.shape}\")\n",
    "print(f\"\\nFeature Matrix Size: {X.nbytes / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance Test 1: Matrix Operations\n",
    "\n",
    "We'll perform large-scale matrix operations including correlation matrix computation and covariance calculations. These operations are fundamental in semiconductor data analysis for identifying parameter relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU Version: Matrix Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TEST 1: MATRIX OPERATIONS (CPU)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Use NumPy for CPU computation\n",
    "X_cpu = X.copy()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix_cpu = np.corrcoef(X_cpu.T)\n",
    "\n",
    "# Compute covariance matrix\n",
    "cov_matrix_cpu = np.cov(X_cpu.T)\n",
    "\n",
    "# Matrix multiplication\n",
    "result_cpu = np.dot(X_cpu.T, X_cpu)\n",
    "\n",
    "cpu_time_matrix = time.time() - start_time\n",
    "\n",
    "print(f\"\\nâœ“ Correlation Matrix Shape: {corr_matrix_cpu.shape}\")\n",
    "print(f\"âœ“ Covariance Matrix Shape: {cov_matrix_cpu.shape}\")\n",
    "print(f\"âœ“ Matrix Multiplication Result Shape: {result_cpu.shape}\")\n",
    "print(f\"\\nâ± CPU Execution Time: {cpu_time_matrix:.2f} seconds\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Version: Matrix Operations\n",
    "\n",
    "Now we'll perform the same operations using GPU acceleration with CuPy. If GPU is not available, this section will be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GPU_AVAILABLE:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"TEST 1: MATRIX OPERATIONS (GPU)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Transfer data to GPU\n",
    "    X_gpu = cp.array(X)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Compute correlation matrix on GPU\n",
    "    corr_matrix_gpu = cp.corrcoef(X_gpu.T)\n",
    "    \n",
    "    # Compute covariance matrix on GPU\n",
    "    cov_matrix_gpu = cp.cov(X_gpu.T)\n",
    "    \n",
    "    # Matrix multiplication on GPU\n",
    "    result_gpu = cp.dot(X_gpu.T, X_gpu)\n",
    "    \n",
    "    # Synchronize GPU\n",
    "    cp.cuda.Stream.null.synchronize()\n",
    "    \n",
    "    gpu_time_matrix = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nâœ“ Correlation Matrix Shape: {corr_matrix_gpu.shape}\")\n",
    "    print(f\"âœ“ Covariance Matrix Shape: {cov_matrix_gpu.shape}\")\n",
    "    print(f\"âœ“ Matrix Multiplication Result Shape: {result_gpu.shape}\")\n",
    "    print(f\"\\nâ± GPU Execution Time: {gpu_time_matrix:.2f} seconds\")\n",
    "    print(f\"ðŸš€ Speedup: {cpu_time_matrix / gpu_time_matrix:.2f}x faster\")\n",
    "    print(\"=\" * 70)\n",
    "else:\n",
    "    print(\"\\nâš  GPU not available. Skipping GPU matrix operations.\")\n",
    "    print(\"  Enable GPU in Colab: Runtime -> Change runtime type -> GPU\")\n",
    "    gpu_time_matrix = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance Test 2: Statistical Analysis\n",
    "\n",
    "We'll perform comprehensive statistical analysis including mean, standard deviation, percentiles, and other statistical measures across all test parameters. This is crucial for understanding the distribution of semiconductor test results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU Version: Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TEST 2: STATISTICAL ANALYSIS (CPU)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Compute various statistics\n",
    "mean_cpu = np.mean(X_cpu, axis=0)\n",
    "std_cpu = np.std(X_cpu, axis=0)\n",
    "median_cpu = np.median(X_cpu, axis=0)\n",
    "percentile_25_cpu = np.percentile(X_cpu, 25, axis=0)\n",
    "percentile_75_cpu = np.percentile(X_cpu, 75, axis=0)\n",
    "min_cpu = np.min(X_cpu, axis=0)\n",
    "max_cpu = np.max(X_cpu, axis=0)\n",
    "\n",
    "cpu_time_stats = time.time() - start_time\n",
    "\n",
    "print(f\"\\nâœ“ Computed statistics for {len(feature_cols)} features\")\n",
    "print(f\"âœ“ Mean values shape: {mean_cpu.shape}\")\n",
    "print(f\"âœ“ Std deviation shape: {std_cpu.shape}\")\n",
    "print(f\"\\nâ± CPU Execution Time: {cpu_time_stats:.2f} seconds\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Version: Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GPU_AVAILABLE:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"TEST 2: STATISTICAL ANALYSIS (GPU)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Compute various statistics on GPU\n",
    "    mean_gpu = cp.mean(X_gpu, axis=0)\n",
    "    std_gpu = cp.std(X_gpu, axis=0)\n",
    "    median_gpu = cp.median(X_gpu, axis=0)\n",
    "    percentile_25_gpu = cp.percentile(X_gpu, 25, axis=0)\n",
    "    percentile_75_gpu = cp.percentile(X_gpu, 75, axis=0)\n",
    "    min_gpu = cp.min(X_gpu, axis=0)\n",
    "    max_gpu = cp.max(X_gpu, axis=0)\n",
    "    \n",
    "    # Synchronize GPU\n",
    "    cp.cuda.Stream.null.synchronize()\n",
    "    \n",
    "    gpu_time_stats = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nâœ“ Computed statistics for {len(feature_cols)} features\")\n",
    "    print(f\"âœ“ Mean values shape: {mean_gpu.shape}\")\n",
    "    print(f\"âœ“ Std deviation shape: {std_gpu.shape}\")\n",
    "    print(f\"\\nâ± GPU Execution Time: {gpu_time_stats:.2f} seconds\")\n",
    "    print(f\"ðŸš€ Speedup: {cpu_time_stats / gpu_time_stats:.2f}x faster\")\n",
    "    print(\"=\" * 70)\n",
    "else:\n",
    "    print(\"\\nâš  GPU not available. Skipping GPU statistical analysis.\")\n",
    "    gpu_time_stats = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Test 3: Principal Component Analysis (PCA)\n",
    "\n",
    "PCA is used in semiconductor analysis to reduce the dimensionality of test data while preserving the most important variance. This helps identify the key parameters that distinguish passing from failing chips."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU Version: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TEST 3: PRINCIPAL COMPONENT ANALYSIS (CPU)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Standardize features\n",
    "scaler_cpu = StandardScaler()\n",
    "X_scaled_cpu = scaler_cpu.fit_transform(X_cpu)\n",
    "\n",
    "# Apply PCA\n",
    "pca_cpu = PCA(n_components=20)\n",
    "X_pca_cpu = pca_cpu.fit_transform(X_scaled_cpu)\n",
    "\n",
    "cpu_time_pca = time.time() - start_time\n",
    "\n",
    "print(f\"\\nâœ“ Original dimensions: {X_cpu.shape}\")\n",
    "print(f\"âœ“ Reduced dimensions: {X_pca_cpu.shape}\")\n",
    "print(f\"âœ“ Explained variance ratio: {pca_cpu.explained_variance_ratio_.sum():.4f}\")\n",
    "print(f\"\\nâ± CPU Execution Time: {cpu_time_pca:.2f} seconds\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Version: PCA\n",
    "\n",
    "For GPU-accelerated PCA, we'll use CuPy for matrix operations. Note that scikit-learn's PCA doesn't directly support GPU, but the underlying matrix operations can be accelerated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GPU_AVAILABLE:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"TEST 3: PRINCIPAL COMPONENT ANALYSIS (GPU)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Standardize features on GPU\n",
    "    mean_gpu_pca = cp.mean(X_gpu, axis=0)\n",
    "    std_gpu_pca = cp.std(X_gpu, axis=0)\n",
    "    X_scaled_gpu = (X_gpu - mean_gpu_pca) / std_gpu_pca\n",
    "    \n",
    "    # Compute covariance matrix on GPU\n",
    "    cov_matrix_pca = cp.cov(X_scaled_gpu.T)\n",
    "    \n",
    "    # Compute eigenvalues and eigenvectors on GPU\n",
    "    eigenvalues, eigenvectors = cp.linalg.eigh(cov_matrix_pca)\n",
    "    \n",
    "    # Sort by eigenvalues (descending)\n",
    "    idx = cp.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[idx]\n",
    "    eigenvectors = eigenvectors[:, idx]\n",
    "    \n",
    "    # Select top 20 components\n",
    "    components_gpu = eigenvectors[:, :20]\n",
    "    X_pca_gpu = cp.dot(X_scaled_gpu, components_gpu)\n",
    "    \n",
    "    # Synchronize GPU\n",
    "    cp.cuda.Stream.null.synchronize()\n",
    "    \n",
    "    gpu_time_pca = time.time() - start_time\n",
    "    \n",
    "    explained_variance = eigenvalues[:20] / cp.sum(eigenvalues)\n",
    "    \n",
    "    print(f\"\\nâœ“ Original dimensions: {X_gpu.shape}\")\n",
    "    print(f\"âœ“ Reduced dimensions: {X_pca_gpu.shape}\")\n",
    "    print(f\"âœ“ Explained variance ratio: {cp.sum(explained_variance).get():.4f}\")\n",
    "    print(f\"\\nâ± GPU Execution Time: {gpu_time_pca:.2f} seconds\")\n",
    "    print(f\"ðŸš€ Speedup: {cpu_time_pca / gpu_time_pca:.2f}x faster\")\n",
    "    print(\"=\" * 70)\n",
    "else:\n",
    "    print(\"\\nâš  GPU not available. Skipping GPU PCA.\")\n",
    "    gpu_time_pca = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Test 4: Machine Learning Model Training\n",
    "\n",
    "We'll train a Random Forest classifier to predict chip pass/fail status based on test parameters. This represents a real-world semiconductor analysis task where we need to identify patterns that distinguish good chips from defective ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TEST 4: MACHINE LEARNING MODEL TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cpu, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]:,}\")\n",
    "print(f\"Test set size: {X_test.shape[0]:,}\")\n",
    "\n",
    "# Train Random Forest (CPU-based)\n",
    "start_time = time.time()\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "cpu_time_ml = time.time() - start_time\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = rf_model.predict(X_test)\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "print(f\"\\nâœ“ Model trained successfully\")\n",
    "print(f\"âœ“ Model accuracy: {accuracy:.4f}\")\n",
    "print(f\"\\nâ± Training Time: {cpu_time_ml:.2f} seconds\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Note: Random Forest in scikit-learn doesn't have direct GPU support\n",
    "# For GPU-accelerated ML, libraries like XGBoost or cuML would be used\n",
    "# This test demonstrates CPU-only ML workload\n",
    "gpu_time_ml = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance Summary and Comparison\n",
    "\n",
    "Let's summarize all the performance tests and visualize the speedup achieved with GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance summary\n",
    "results = {\n",
    "    'Test': ['Matrix Operations', 'Statistical Analysis', 'PCA', 'ML Training'],\n",
    "    'CPU Time (s)': [cpu_time_matrix, cpu_time_stats, cpu_time_pca, cpu_time_ml],\n",
    "    'GPU Time (s)': [gpu_time_matrix, gpu_time_stats, gpu_time_pca, gpu_time_ml]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Calculate speedup where GPU is available\n",
    "results_df['Speedup'] = results_df.apply(\n",
    "    lambda row: row['CPU Time (s)'] / row['GPU Time (s)'] if row['GPU Time (s)'] is not None else None,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if GPU_AVAILABLE:\n",
    "    total_cpu_time = results_df['CPU Time (s)'].sum()\n",
    "    total_gpu_time = results_df['GPU Time (s)'].dropna().sum()\n",
    "    overall_speedup = total_cpu_time / total_gpu_time\n",
    "    time_saved = total_cpu_time - total_gpu_time\n",
    "    \n",
    "    print(f\"\\nðŸ“Š OVERALL PERFORMANCE:\")\n",
    "    print(f\"   Total CPU Time: {total_cpu_time:.2f} seconds\")\n",
    "    print(f\"   Total GPU Time: {total_gpu_time:.2f} seconds\")\n",
    "    print(f\"   Overall Speedup: {overall_speedup:.2f}x faster\")\n",
    "    print(f\"   Time Saved: {time_saved:.2f} seconds ({time_saved/60:.2f} minutes)\")\n",
    "    print(f\"   Efficiency Gain: {(1 - total_gpu_time/total_cpu_time)*100:.1f}%\")\n",
    "    print(\"=\" * 70)\n",
    "else:\n",
    "    print(\"\\nâš  Run this notebook on Google Colab with GPU enabled to see speedup!\")\n",
    "    print(\"  Instructions: Runtime -> Change runtime type -> GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize performance comparison\n",
    "if GPU_AVAILABLE:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Bar chart comparing CPU vs GPU times\n",
    "    tests = results_df['Test']\n",
    "    x = np.arange(len(tests))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = axes[0].bar(x - width/2, results_df['CPU Time (s)'], width, \n",
    "                        label='CPU', color='#FFB6C6', alpha=0.8)\n",
    "    bars2 = axes[0].bar(x + width/2, results_df['GPU Time (s)'].fillna(0), width, \n",
    "                        label='GPU', color='#ADD8E6', alpha=0.8)\n",
    "    \n",
    "    axes[0].set_xlabel('Test Type', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_ylabel('Execution Time (seconds)', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_title('CPU vs GPU Execution Time Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].set_xticklabels(tests, rotation=45, ha='right')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Speedup chart\n",
    "    speedup_data = results_df[results_df['Speedup'].notna()]\n",
    "    bars = axes[1].bar(speedup_data['Test'], speedup_data['Speedup'], \n",
    "                       color='#90EE90', alpha=0.8)\n",
    "    axes[1].axhline(y=1, color='red', linestyle='--', linewidth=2, label='No Speedup')\n",
    "    axes[1].set_xlabel('Test Type', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('Speedup Factor (x)', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_title('GPU Speedup Over CPU', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xticklabels(speedup_data['Test'], rotation=45, ha='right')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        axes[1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.2f}x',\n",
    "                    ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    # Show only CPU times when GPU is not available\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    bars = ax.bar(results_df['Test'], results_df['CPU Time (s)'], \n",
    "                  color='#FFB6C6', alpha=0.8)\n",
    "    ax.set_xlabel('Test Type', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Execution Time (seconds)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('CPU Execution Time (GPU Not Available)', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticklabels(results_df['Test'], rotation=45, ha='right')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nðŸ’¡ TIP: Enable GPU in Google Colab to see dramatic speedup!\")\n",
    "    print(\"   Runtime -> Change runtime type -> Hardware accelerator -> GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Findings and Insights\n",
    "\n",
    "### Performance Analysis\n",
    "\n",
    "The performance comparison demonstrates the significant computational advantages of GPU acceleration for large-scale semiconductor data analysis:\n",
    "\n",
    "1. **Matrix Operations**: GPU excels at parallel matrix computations, showing substantial speedup for correlation and covariance calculations.\n",
    "\n",
    "2. **Statistical Analysis**: Batch statistical operations benefit greatly from GPU's parallel processing capabilities.\n",
    "\n",
    "3. **PCA**: Dimensionality reduction through PCA involves heavy matrix operations, making it ideal for GPU acceleration.\n",
    "\n",
    "4. **Machine Learning**: While Random Forest in scikit-learn is CPU-optimized, GPU-based ML libraries (XGBoost, cuML) can provide additional speedup.\n",
    "\n",
    "### When to Use GPU\n",
    "\n",
    "GPU acceleration is most beneficial when:\n",
    "- Working with large datasets (>10,000 samples)\n",
    "- Performing matrix-heavy operations\n",
    "- Running iterative algorithms\n",
    "- Processing multiple batches in parallel\n",
    "\n",
    "### Practical Implications for Semiconductor Analysis\n",
    "\n",
    "For post-silicon validation engineers:\n",
    "- **Faster iteration**: Quickly test multiple analysis approaches\n",
    "- **Real-time analysis**: Process test data as it's generated\n",
    "- **Scalability**: Handle larger datasets without proportional time increase\n",
    "- **Cost efficiency**: Reduce compute time and associated costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "This notebook demonstrated the performance difference between CPU and GPU computing for semiconductor data analysis. Key takeaways:\n",
    "\n",
    "- âœ… GPU acceleration provides significant speedup for matrix operations and statistical analysis\n",
    "- âœ… Google Colab's free GPU makes advanced computing accessible\n",
    "- âœ… The same code can run on both CPU and GPU with minimal modifications\n",
    "- âœ… For production semiconductor analysis, GPU acceleration can save hours of computation time\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "To further optimize your semiconductor data analysis:\n",
    "1. Explore GPU-accelerated ML libraries (XGBoost, cuML)\n",
    "2. Implement batch processing for even larger datasets\n",
    "3. Use mixed precision computing for additional speedup\n",
    "4. Consider distributed computing for multi-GPU setups"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
